# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: serverless/instrumentation/v1/dev_mode.proto, serverless/instrumentation/v1/event.proto, serverless/instrumentation/v1/log.proto, serverless/instrumentation/v1/metric.proto, serverless/instrumentation/v1/request_response.proto, serverless/instrumentation/v1/trace.proto
# plugin: python-betterproto
from dataclasses import dataclass
from typing import (
    List,
    Optional,
)

import betterproto

from ..tags import v1 as _tags_v1__


class RequestResponseOrigin(betterproto.Enum):
    ORIGIN_UNSPECIFIED = 0
    """Not disclosed (not applicable as property is required)"""

    ORIGIN_REQUEST = 1
    """Function request event"""

    ORIGIN_RESPONSE = 2
    """Function handler response"""


@dataclass(eq=False, repr=False)
class EventPayload(betterproto.Message):
    """
    An EventPayload is a message that will contain any number of Events plus
    the global tags required by our Serverless Ingest Platform.
    """

    sls_tags: "_tags_v1__.SlsTags" = betterproto.message_field(1)
    events: List["Event"] = betterproto.message_field(2)
    """
    A list of Events to be ingested. Ingest does not impose a limit on the
    number of Events in a single payload. It is the responsibility of the Event
    producer to limit the size of payloads based on their own requirements.
    """


@dataclass(eq=False, repr=False)
class Event(betterproto.Message):
    id: bytes = betterproto.bytes_field(1)
    """
    The Event ID, this will be a random 8-byte ID encoded as a length 16
    lowercase hex string.
    """

    trace_id: bytes = betterproto.bytes_field(2)
    """
    The Trace ID, this will be a random 16-byte ID encoded as a length 32
    lowercase hex string. The Trace ID is what is used to group all spans for
    specific trace together.
    """

    span_id: Optional[bytes] = betterproto.bytes_field(
        3, optional=True, group="_span_id"
    )
    """
    An optional Span ID to be used to create to show the span context that the
    event was generated in. In practical terms, every span except the root span
    will have a parent span ID.
    """

    timestamp_unix_nano: int = betterproto.fixed64_field(4)
    """The timestamp of when the Event happened in nanoseconds from EPOCH."""

    event_name: str = betterproto.string_field(5)
    """
    The name that is used internal in the Serverless platform to identify the
    event.
    """

    custom_tags: Optional[str] = betterproto.string_field(
        6, optional=True, group="_custom_tags"
    )
    """
    The optional customTags that can be attached to an event when published.
    This is expected to be a JSON object in string format.
    """

    custom_fingerprint: Optional[str] = betterproto.string_field(
        7, optional=True, group="_custom_fingerprint"
    )
    """
    The optional custom fingerprint that will override our default
    fingerprinting approach
    """

    tags: "_tags_v1__.Tags" = betterproto.message_field(15)
    """A message containing any number of Tagsets."""


@dataclass(eq=False, repr=False)
class TracePayload(betterproto.Message):
    """
    TracePayload is a message that will contain any number of Spans plus the
    global tags required by our Serverless Ingest Platform. A TracePayload DOES
    NOT necessarily mean that it is a complete Trace. It may contain only a
    subset of Spans that will make up the complete Trace.
    """

    sls_tags: "_tags_v1__.SlsTags" = betterproto.message_field(1)
    spans: List["Span"] = betterproto.message_field(3)
    """
    A list of Spans to be ingest. Ingest does not impose a limit on the number
    of Spans in a single payload. It is the responsibility of the Span
    producers to limit the size of payloads based on their own requirements.
    """

    events: List["Event"] = betterproto.message_field(4)
    """
    A list of Events to be ingested. Ingest does not impose a limit on the
    number of Events in a single payload. It is the responsibility of the Event
    producers to limit the size of paylaods based on their own requirements.
    """

    custom_tags: Optional[str] = betterproto.string_field(
        5, optional=True, group="_custom_tags"
    )
    """
    The optional custom trace tags to be set by the user This is expected to be
    a JSON object in string format.
    """

    is_sampled_out: Optional[bool] = betterproto.bool_field(
        6, optional=True, group="_is_sampled_out"
    )
    """
    Whether the trace payload represents sampled out invocation and in result
    contains just core spans and no events
    """


@dataclass(eq=False, repr=False)
class Span(betterproto.Message):
    id: bytes = betterproto.bytes_field(1)
    """
    The Span ID, this will be a random 8-byte ID encoded as a length 16
    lowercase hex string.
    """

    trace_id: bytes = betterproto.bytes_field(2)
    """
    The Trace ID, this will be a random 16-byte ID encoded as a length 32
    lowercase hex string. The Trace ID is what is used to group all spans for
    specific trace together.
    """

    parent_span_id: Optional[bytes] = betterproto.bytes_field(
        3, optional=True, group="_parent_span_id"
    )
    """
    An optional Parent Span ID to be used to create a trace's Span Dependency
    graph. In practical terms, every span except the root span will have a
    parent span ID.
    """

    name: str = betterproto.string_field(4)
    """
    The name of the span describes the type of span that is being produced.
    currently have a limited set of span names - aws.lambda: Spans the full
    invocation duration of a lambda function - aws.lambda.invocation: Spans the
    cold-start duration of a lambda function
    """

    start_time_unix_nano: int = betterproto.fixed64_field(5)
    """The start time of the span in nanoseconds from EPOCH."""

    end_time_unix_nano: int = betterproto.fixed64_field(6)
    """
    The end time of the span in nanoseconds from EPOCH. An important invariant
    to keep in mind is that the root span will always have the latest end time.
    """

    tags: "_tags_v1__.Tags" = betterproto.message_field(7)
    """A message containing any number of Tagsets"""

    input: Optional[str] = betterproto.string_field(8, optional=True, group="_input")
    """Eventual input body (e.g. HTTP request body)"""

    output: Optional[str] = betterproto.string_field(9, optional=True, group="_output")
    """Eventual output body (e.g. HTTP response body)"""

    timestamp: Optional[int] = betterproto.fixed64_field(
        10, optional=True, group="_timestamp"
    )
    """The timestamp that is created in ingestion as the search key"""

    is_historical: Optional[bool] = betterproto.bool_field(
        11, optional=True, group="_is_historical"
    )
    """
    Is historical is addedd via ingestion so that we can tell the differnce
    between historical payloads and live streamed payloads
    """

    type: Optional[str] = betterproto.string_field(12, optional=True, group="_type")
    """
    Type is used to determine the kind of document that is being send via a
    livestream
    """

    custom_tags: Optional[str] = betterproto.string_field(
        13, optional=True, group="_custom_tags"
    )
    """
    The optional custom tags to be set by the user This is expected to be a
    JSON object in string format.
    """


@dataclass(eq=False, repr=False)
class RequestResponse(betterproto.Message):
    """
    RequestResponse is the AWS Lambda Event and Response Data. In the
    Serverless Platform there will be two of these payloads One for Event
    payload and then one for the payload returned at the end of the function
    invocation.
    """

    sls_tags: "_tags_v1__.SlsTags" = betterproto.message_field(1)
    """The Global Serverless Platform Tags"""

    trace_id: Optional[bytes] = betterproto.bytes_field(
        2, optional=True, group="_trace_id"
    )
    """The trace Id of the invocation"""

    span_id: Optional[bytes] = betterproto.bytes_field(
        3, optional=True, group="_span_id"
    )
    """
    The span id of the root Lambda Span that request data is attached to on
    ingest.
    """

    request_id: Optional[str] = betterproto.string_field(
        4, optional=True, group="_request_id"
    )
    """The Lambda Request Id."""

    body: Optional[str] = betterproto.string_field(11, optional=True, group="_body")
    """
    JSON string of the request or the response body In case of response may be
    omited if lambda resolved with no value
    """

    origin: "RequestResponseOrigin" = betterproto.enum_field(12)
    """Type of body"""

    tags: Optional["_tags_v1__.Tags"] = betterproto.message_field(
        7, optional=True, group="_tags"
    )
    """A message containing any number of Tagsets"""

    is_historical: Optional[bool] = betterproto.bool_field(
        8, optional=True, group="_is_historical"
    )
    """
    Is historical is addedd via ingestion so that we can tell the differnce
    between historical payloads and live streamed payloads
    """

    type: Optional[str] = betterproto.string_field(9, optional=True, group="_type")
    """
    Type is used to determine the kind of document that is being send via a
    livestream
    """

    timestamp: Optional[int] = betterproto.fixed64_field(
        10, optional=True, group="_timestamp"
    )
    """The timestamp of when the req/res data was generated."""


@dataclass(eq=False, repr=False)
class DevModePayload(betterproto.Message):
    """
    A DevMode Payload is a message that will contain reqRes data or span data
    that is forwarded to ingest via the internal extension
    """

    account_id: str = betterproto.string_field(1)
    """The AWS Account ID where this payload originated from"""

    region: str = betterproto.string_field(2)
    """The AWS Region where this payload originated from"""

    request_id: str = betterproto.string_field(3)
    """The lambda request id where this payload originated from"""

    telemetry: Optional["LambdaTelemetry"] = betterproto.message_field(
        6, optional=True, group="_telemetry"
    )
    """Extracted Lambda Telemetry API data"""

    trace: "TracePayload" = betterproto.message_field(4, group="payload")
    """
    The set of lambda traces that were generated via an internal extension
    """

    request_response: "RequestResponse" = betterproto.message_field(5, group="payload")
    """The req or response data from the instrumented lambda function"""


@dataclass(eq=False, repr=False)
class LambdaTelemetry(betterproto.Message):
    """
    Lambda Telemetry API data. This data is only available for lambda functions
    that have access to the telemetry API so it will not be included in all
    regions.
    """

    init_duration_ms: Optional[int] = betterproto.uint32_field(
        1, optional=True, group="_init_duration_ms"
    )
    """
    Init duration in milliseconds as reported by the metrics on the
    platform.initReport event
    """

    runtime_duration_ms: Optional[int] = betterproto.uint32_field(
        2, optional=True, group="_runtime_duration_ms"
    )
    """
    Internal runtime duration in milliseconds as reported by the metrics on the
    platform.runtimeDone event
    """

    runtime_response_latency_ms: Optional[int] = betterproto.uint32_field(
        3, optional=True, group="_runtime_response_latency_ms"
    )
    """
    Internal runtime duration in milliseconds as reported by the
    responseLatency span on the platform.runtimeDone event
    """


@dataclass(eq=False, repr=False)
class LogPayload(betterproto.Message):
    """
    A LogPayload is a message that will contain any number of LogEvents plus
    the global tags required by our Serverless Ingest Platform.
    """

    sls_tags: "_tags_v1__.SlsTags" = betterproto.message_field(1)
    log_events: List["LogEvent"] = betterproto.message_field(2)
    """
    A list of LogEvents to be ingested. Ingest does not impose a limit on the
    number of LogEvents in a single payload. It is the responsibility of the
    LogEvents' producers to limit the size of payloads based on their own
    requirements.
    """


@dataclass(eq=False, repr=False)
class LogEvent(betterproto.Message):
    timestamp: int = betterproto.fixed64_field(2)
    """The timestamp of when the LogEvent was created."""

    trace_id: Optional[str] = betterproto.string_field(
        8, optional=True, group="_trace_id"
    )
    """
    The Trace Id that the log's are linked to. When ingesting LogEvents, ingest
    will attempt to infer the request_id from the payload and attach it. If it
    is not able to, then it will attempt to reconcile later.
    """

    body: str = betterproto.string_field(9)
    """The LogEvent's body."""

    severity_text: str = betterproto.string_field(10)
    """The calculated severity text value for a log"""

    severity_number: int = betterproto.uint64_field(11)
    """The calculated severity text value for a log"""

    tags: Optional["_tags_v1__.Tags"] = betterproto.message_field(
        12, optional=True, group="_tags"
    )
    """A message containing any number of Tagsets"""

    is_historical: Optional[bool] = betterproto.bool_field(
        13, optional=True, group="_is_historical"
    )
    """
    Is historical is addedd via ingestion so that we can tell the differnce
    between historical payloads and live streamed payloads
    """

    type: Optional[str] = betterproto.string_field(14, optional=True, group="_type")
    """
    Type is used to determine the kind of document that is being send via a
    livestream
    """


@dataclass(eq=False, repr=False)
class MetricPayload(betterproto.Message):
    """
    A MetricPayload is a message that will contain any number of Metrics plus
    the global tags required by our Serverless Ingest Platform.
    """

    sls_tags: "_tags_v1__.SlsTags" = betterproto.message_field(1)
    metrics: List["Metric"] = betterproto.message_field(2)
    """
    A list of Metrics to be ingested. Ingest does not impose a limit on the
    number of Metrics in a single payload. It is the responsibility of the
    metrics' producers to limit the size of payloads based on their own
    requirements.
    """


@dataclass(eq=False, repr=False)
class Metric(betterproto.Message):
    id: bytes = betterproto.bytes_field(1)
    """
    A unique id for the metric measurement. If this is a Metric from, The
    metric stream then it will be a randomly generated UUID at ingest time.
    """

    name: str = betterproto.string_field(2)
    """
    The name of the metric. If this is a Metric from the Metric stream, it will
    be in the format amazonaws.com/<metric_namespace>/<metric_name>. The name
    is what will be mapped into influx.
    """

    start_time_unix_nano: int = betterproto.fixed64_field(3)
    """
    The start time of the measure. If this is a Metric from the Metric stream,
    it will be the Cloudwatch startTime property.
    """

    end_time_unix_nano: int = betterproto.fixed64_field(4)
    """
    The end time of the measure. If this is a Metric from the Metric stream, it
    will be the Cloudwatch endTime property.
    """

    tags: str = betterproto.string_field(5)
    """
    Tags for the Metric. Any tags can be placed in this field, however, ingest
    will only write allowlisted, low cardinality tags to Influx.
    """

    count: int = betterproto.fixed64_field(6)
    """
    The number of datapoints for the Metric. If this is a Metric from the
    Metric stream, it will be the SampleCount from Cloudwatch
    """

    sum: float = betterproto.double_field(7)
    """The sum of the datapoints for the Metric."""

    quantile_values: List["MetricValueAtQuantile"] = betterproto.message_field(8)
    """
    List of quantile values. If this is a Metric from the Metric stream, it
    will by default have quantile 0.0 and 1.0 to represent the min and max
    values. If defined during Metric's Stream setup it will have additional
    quantiles as well.
    """


@dataclass(eq=False, repr=False)
class MetricValueAtQuantile(betterproto.Message):
    """
    A value at a given quantile of the distribution. If a Metric has multiple
    samples, the Min and Max will be represented by, 1. Quantile = 1.0, is the
    max value 2. Quantile = 0.0, is the min value
    """

    quantile: float = betterproto.double_field(1)
    value: float = betterproto.double_field(2)
