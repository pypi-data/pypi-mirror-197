# Define which PyTorch optimizer to use for both encoder and decoder networks
optimizer_conf: &optimizer_conf
  class: torch.optim.Adam
  kwargs: { lr: 0.0001 }

# Define a set of character that the model is capable of recognizing
charset: &charset
  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ

# Define a loss function to use and transform class that transforms loss inputs.
# This specifies the masked cross entropy loss with label smoothing
loss_conf: &loss_conf
  class: lafhterlearn.loss_functions.MaskedCrossEntropy
  kwargs: { reduction: sum, label_smoothing: 0.6 }
  transform:
    class: lafhterlearn.loss_functions.LossTargetTransform
    kwargs: { charset: *charset }

# Define Character Error Rate (CER) metric
cer_conf: &cer_conf
  class: torchmetrics.CharErrorRate
  transform:
    class: lafhterlearn.decoding.DecodeBatchTransform
    kwargs: { charset: *charset }

# Define Word Error Rate (CER) metric
wer_conf: &wer_conf
  class: torchmetrics.WordErrorRate
  transform:
    class: lafhterlearn.decoding.DecodeBatchTransform
    kwargs: { charset: *charset }

# Define which device to use, "auto" means pick cuda when available
device: auto

# Define maximum width of images. When set, images will be right padded
# using white background to be of max_image_width width.
# Otherwise, each image in a given batch will be right padded to have the width
# of the image with the largest width in that batch
max_image_width: null

# Define whether preprocessing pipeline should include operation which resizes
# all images so that they have height equal to image_height whilst keeping the aspect ratio
resize_images: False

# Define maximum height of images.
# Images taller than image_height will be resized
# to the image_height height preserving the aspect ratio.
# Images with height smaller than image_height will be padded to the bottom to
# have specified image_height
image_height: &image_height
  64

# Define the number of hidden units in RNN of the encoder
hidden_size: &hidden_size
  128

# Define decoder parameters such as number of hidden units,
# number of convolutional filters (in the attention network) and their kernel size
decoder_params:
  decoder_hidden_size: *hidden_size
  filters: 10
  kernel_size: 5

# Define directory with fonts (expects files with .otf and .ttf extensions)
fonts_dir: fonts

# Define configuration options for synthetic image generator.
# Every image will be grayscale image.
# Each option sets the range of values to choose from uniformly and randomly
data_generator_options:
  bg_range: [ 200, 255 ] # background intensities
  color_range: [ 0, 50 ] # foreground (writing color) intensities
  stroke_fill_range: [ 0, 50 ] # intensities for stroke fill color
  font_size_range: [ 50, 100 ] # font sizes in pixels
  rotation_range: [ 0, 0 ] # rotation angles measured in degrees
  spaces_range: [ 0, 2 ] # the number of narrow spaces between word letters

# Define the number of synthetic examples to generate per epoch.
# It is important to remember that examples shown in previous epoch will not be
# reused in a consecutive ones. Each epoch will work with different synthetic training examples
# generated on the fly. In fact, the model will not see any image more than once. Thus, epochs are
# used here only for convenience to help track model performance and save checkpoints.
training_set_size: 50000

# Define the number of synthetic examples to use to compute metrics.
# In this case, validation examples generated for previous epoch will be reused
# in consecutive ones.
validation_set_size: 2500

# Define batch size. The same value is used for training on both synthetic and real images.
# The same batch size is used when computing metrics and making batch predictions.
batch_size: 32

# Define the number of parallel workers in data loader.
# It is strongly recommended not to change this value
num_workers: 0

# Define the loss function
loss_function: *loss_conf

# Define encoder optimizer
encoder_optimizer: *optimizer_conf

# Define decoder optimizer
decoder_optimizer: *optimizer_conf

# Define a set of metrics to compute on synthetic training data with augmentation.
# The form metric_name: metric_config
# Uncomment the line starting with WER to add Word Error Rate to the set of metric to compute
training_metrics:
  loss: *loss_conf # masked cross entropy
  CER: *cer_conf   # Character Error Rate (CER)
  #WER: *wer_conf  # Word Error Rate (WER)

# Define a set of metrics to compute on synthetic validation data without augmentation
validation_metrics:
  val loss: *loss_conf
  val CER: *cer_conf
  #val WER: *wer_conf

# Define a set of metrics to compute on real images dataset without applying augmentation.
# This is going to be a dataset with distribution close to one seen in production
test_metrics:
    test loss: *loss_conf
    test CER: *cer_conf
    #test WER: *wer_conf

# whether to run inference in close loop mode when calculating test metrics
# which means that decoder RNN will not have access to the right transcript,
# rather on each step decoder will be fed most likely token predicted by it on previous step
close_loop_mode:
    test loss: False
    test CER: True
    #test WER: True

# Define relative path to the directory containing all the information
# about the training session such as model architecture parameters, checkpoints,
# training configuration, history, etc.
session_dir: session

# Define for each dataset fraction of examples that will be used for computing metrics
evaluation_steps:
  training_set: 0.1
  validation_set: 1.0
  test_set: 0.5

# Define the number of epochs for the first phase (training the model on synthetic images)
epochs: 50

# Define the number of epochs for the second phase (synthetic-to-real adaptation)
tuning_epochs: 50

# Define the word sampler class. Available sampler classes are implemented in
# the lafhterlearn.word_samplers module: UniformSampler, FrequencyBasedSampler, NgramBasedSampler.
# See readme file for more details on different samplers and their use.
word_sampler: lafhterlearn.word_samplers.FrequencyBasedSampler

# Define a path to a file containing data consumable by chosen word sampler.
#
# UniformSampler expects a plain text file listing words, one per line
#
# FrequencyBasedSampler expects a text file in CSV format, where each line contains
# word and its probability separated by a comma
#
# NgramBasedSampler expects a file in HD5 format storing the n-gram model
sampler_data_file: word_distribution.csv

# Define optional key-word arguments to pass to the sampler class
# UniformSampler class has no extra arguments
#
# FrequencyBasedSampler class has only one key-word argument called sampling_batch_size
# (for efficiency purposes, the sampler generates a bunch of random values in one bulk operation
# and puts them in the buffer. In consecutive calls it retrieves them from a buffer until it becomes empty.
# The parameter defines how many values will be generated in one bulk operation)
#
# NgramBasedSampler class has one key-word argument num_words
# It specifies how many words should contain output text sequence (10 words by default)
sampler_kwargs:
  sampling_batch_size: 1024


# Define the path to the real image directory
tuning_data_dir: tuning_data

# Define a confidence threshold used in the second phase when the model is trained on images
# it labels by itself. Must be between 0 and 0.6
confidence_threshold: 0.4

# Define which trainer class to use during the second phase.
# If the value is not "simple_trainer", fine-tuning procedure will
# involve consistency regularization
tuning_trainer_factory: simple_trainer

# Define configuration options applied when training with consistency regularization
weak_augment_options:
  p_augment: 0.4
  target_height: *image_height
  fill: 255
  rotation_degrees_range: [ -5, 5 ]
  blur_size: 3
  blur_sigma: [ 1, 1 ]
  noise_sigma: 10
  should_fit_height: False
